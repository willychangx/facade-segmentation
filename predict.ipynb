{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willychangx/facade-segmentation/blob/main/predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deI9J1sgeR_k"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1Knr0YRtWKf06a9tCHh1HTcgEA8AQy3Cl\n",
        "!unzip /content/segmentation_predict.zip -d /content\n",
        "%rm -rf /content/segmentation_predict.zip\n",
        "\n",
        "%cd /content/segmentation_predict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LaeUVZVeOzB"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXDNZeA6eMl2"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import png\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import random\n",
        "from PIL import Image\n",
        "from colormap.colors import Color, hex2rgb\n",
        "from sklearn.metrics import average_precision_score as ap_score\n",
        "from torch.utils.data import ConcatDataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from dataset import FacadeDataset\n",
        "\n",
        "N_CLASS=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WBwfAgfdy6y"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.n_class = N_CLASS\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), \n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "        )\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "        )\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "        )\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "        )\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=N_CLASS, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        x1 = self.layer1(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x1) # max pool 2x2\n",
        "        x2 = self.layer2(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x2) # max pool 2x2\n",
        "        x3 = self.layer3(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x3) # max pool 2x2\n",
        "        x4 = self.layer4(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x4) # max pool 2x2\n",
        "        x = self.layer5(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        x = torch.cat([x4, x], dim=1)\n",
        "        x = self.layer6(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        x = torch.cat([x3, x], dim=1)\n",
        "        x = self.layer7(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        x = torch.cat([x2, x], dim=1)\n",
        "        x = self.layer8(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        x = torch.cat([x1, x], dim=1)\n",
        "        x = self.layer9(x) # conv 3x3, ReLU, conv 1x1\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Z4YMcgjPAt"
      },
      "source": [
        "def save_label(label, path):\n",
        "    '''\n",
        "    Function for plotting labels.\n",
        "    '''\n",
        "    colormap = [\n",
        "        '#000000', # black, facade\n",
        "        '#0080FF', # blue, others\n",
        "        '#80FF80', # green, pillar\n",
        "        '#FF8000', # orange, window\n",
        "        '#FF0000', # red, balcony\n",
        "    ]\n",
        "    assert(np.max(label)<len(colormap))\n",
        "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
        "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
        "    with open(path, 'wb') as f:\n",
        "        w.write(f, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-vgbvEad4yo"
      },
      "source": [
        "def get_result(testloader, net, device, folder='output_train'):\n",
        "    result = []\n",
        "    cnt = 1\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        cnt = 0\n",
        "        for images, labels in tqdm(testloader, disable=True):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)[0].cpu().numpy()\n",
        "            c, h, w = output.shape\n",
        "            assert(c == N_CLASS)\n",
        "            y = np.zeros((h,w)).astype('uint8')\n",
        "            for i in range(N_CLASS):\n",
        "                mask = output[i]>0.5\n",
        "                y[mask] = i\n",
        "            gt = labels.cpu().data.numpy().astype('uint8')\n",
        "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
        "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
        "            plt.imsave(\n",
        "                './{}/x{}.jpg'.format(folder, cnt),\n",
        "                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n",
        "\n",
        "            cnt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X09D6eM8eEpG"
      },
      "source": [
        "def main():\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # load testing data, data must be in folder /uh_test/ and named 'uh_test_0.jpg'\n",
        "    uh_data = FacadeDataset(flag='uh_test', dataDir='./uh_test/', data_range=(0,1), onehot=False)\n",
        "    uh_loader = DataLoader(uh_data, batch_size=1)\n",
        "\n",
        "    name = 'starter_net'\n",
        "\n",
        "    net = Net().to(device)\n",
        "\n",
        "    net.load_state_dict(torch.load('./models/model_starter_net.pth'))\n",
        "\n",
        "    print('\\nPredicting on UH building image')\n",
        "    res = get_result(uh_loader, net, device, folder='output_train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjxDaDU_eFhm"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}