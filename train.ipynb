{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDPxy0gmItj8DJ91p8erjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willychangx/window-segmentation/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMC5I3as16q"
      },
      "source": [
        "# Download folders. You don't need to change anything, you'll be downloading from my Google Drive.\n",
        "\n",
        "%%capture\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1s2Hh6xuOLHaCMeH2wT_s9wEbJnqx8ZN7\n",
        "!unzip /content/segmentation.zip -d /content\n",
        "\n",
        "%cd /content/segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLxmdtj9z0Xw"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rRDmq_du2Qt"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import png\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from colormap.colors import Color, hex2rgb\n",
        "from sklearn.metrics import average_precision_score as ap_score\n",
        "from torch.utils.data import ConcatDataset, DataLoader, random_split\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from dataset import FacadeDataset\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "N_CLASS=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuZYt4yBrHt-"
      },
      "source": [
        "# images are 256x256\n",
        "torch.manual_seed(0)\n",
        "params = {\n",
        "    'batch_size': 10,\n",
        "    'loss_function': nn.CrossEntropyLoss(),\n",
        "    'learning_rate': 1e-3,\n",
        "    'weight_decay': 1e-5,\n",
        "    'epochs': 32,\n",
        "    'percent': 0.20,\n",
        "    'fold': 5\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akodRK96u_tU"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.n_class = N_CLASS\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=2)\n",
        "        )\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=2)\n",
        "        )\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=2)\n",
        "        )\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=2)\n",
        "        )\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=N_CLASS, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        x1 = self.layer1(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x1) # max pool 2x2\n",
        "        x2 = self.layer2(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x2) # max pool 2x2\n",
        "        x3 = self.layer3(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x3) # max pool 2x2\n",
        "        x4 = self.layer4(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x4) # max pool 2x2\n",
        "        x = self.layer5(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x4.size()[2], x4.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        x = torch.cat([x4, x], dim=1)\n",
        "        x = self.layer6(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x3.size()[2], x3.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        x = torch.cat([x3, x], dim=1)\n",
        "        x = self.layer7(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x2.size()[2], x2.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        x = torch.cat([x2, x], dim=1)\n",
        "        x = self.layer8(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x1.size()[2], x1.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        x = torch.cat([x1, x], dim=1)\n",
        "        x = self.layer9(x) # conv 3x3, ReLU, conv 1x1\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7TgxpVpvres"
      },
      "source": [
        "def save_label(label, path):\n",
        "    '''\n",
        "    Function for ploting labels.\n",
        "    '''\n",
        "    colormap = [\n",
        "        '#000000',\n",
        "        '#0080FF',\n",
        "        '#80FF80',\n",
        "        '#FF8000',\n",
        "        '#FF0000',\n",
        "    ]\n",
        "    assert(np.max(label)<len(colormap))\n",
        "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
        "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
        "    with open(path, 'wb') as f:\n",
        "        w.write(f, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_vqo3uOvvz9"
      },
      "source": [
        "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
        "    '''\n",
        "    Function for training.\n",
        "    '''\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_loss_list = []\n",
        "    net = net.train()\n",
        "    for images, labels in tqdm(trainloader, disable=True):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()\n",
        "        running_loss_list.append(running_loss)\n",
        "    end = time.time()\n",
        "    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n",
        "          (epoch, running_loss, end-start))\n",
        "    return np.mean(running_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNH-8uJVv0Yd"
      },
      "source": [
        "def test(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Function for testing.\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        for images, labels in tqdm(testloader, disable=True):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)\n",
        "            loss = criterion(output, labels)\n",
        "            losses += loss.item()\n",
        "            cnt += 1\n",
        "    print(losses / cnt)\n",
        "    return (losses/cnt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnnDzDHVv4XN"
      },
      "source": [
        "def cal_AP(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Calculate Average Precision\n",
        "    '''\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        preds = [[] for _ in range(5)]\n",
        "        heatmaps = [[] for _ in range(5)]\n",
        "        for images, labels in tqdm(testloader, disable=True):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images).cpu().numpy()\n",
        "            for c in range(5):\n",
        "                preds[c].append(output[:, c].reshape(-1))\n",
        "                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n",
        "\n",
        "        aps = []\n",
        "        for c in range(5):\n",
        "            preds[c] = np.concatenate(preds[c])\n",
        "            heatmaps[c] = np.concatenate(heatmaps[c])\n",
        "            if heatmaps[c].max() == 0:\n",
        "                ap = float('nan')\n",
        "            else:\n",
        "                ap = ap_score(heatmaps[c], preds[c])\n",
        "                aps.append(ap)\n",
        "            print(\"AP = {}\".format(ap))\n",
        "\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7c2L0vPv7Mn"
      },
      "source": [
        "def get_result(testloader, net, device, folder='output_train'):\n",
        "    result = []\n",
        "    cnt = 1\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        cnt = 0\n",
        "        for images, labels in tqdm(testloader, disable=True):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)[0].cpu().numpy()\n",
        "            c, h, w = output.shape\n",
        "            assert(c == N_CLASS)\n",
        "            y = np.zeros((h,w)).astype('uint8')\n",
        "            for i in range(N_CLASS):\n",
        "                mask = output[i]>0.5\n",
        "                y[mask] = i\n",
        "            # gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n",
        "            gt = labels.cpu().data.numpy().astype('uint8')\n",
        "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
        "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
        "            plt.imsave(\n",
        "                './{}/x{}.png'.format(folder, cnt),\n",
        "                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n",
        "\n",
        "            cnt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOrUtgVhv9R2"
      },
      "source": [
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    train_data = FacadeDataset(flag='train', data_range=(0,906), onehot=False)\n",
        "\n",
        "    train_dataset_list = random_split(train_data, [181, 181, 181, 181, 182])\n",
        "\n",
        "    test_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=params['batch_size'])\n",
        "    ap_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=True)\n",
        "    ap_loader = DataLoader(ap_data, batch_size=params['batch_size'])\n",
        "\n",
        "    name = 'starter_net'\n",
        "    \n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    print('\\nStart training')\n",
        "    for fold in range(params['fold']):\n",
        "      print(f'\\nFold {fold+1}')\n",
        "      evaluation_data = train_dataset_list.pop(fold)\n",
        "      evaluation_loader = DataLoader(evaluation_data, batch_size=params['batch_size'])\n",
        "      training_data = ConcatDataset(train_dataset_list)\n",
        "      train_loader = DataLoader(training_data, batch_size=params['batch_size'])\n",
        "\n",
        "      net = Net().to(device)\n",
        "\n",
        "      criterion = params['loss_function']\n",
        "      optimizer = optim.Adam(net.parameters(), params['learning_rate'], weight_decay=params['weight_decay'])\n",
        "\n",
        "      epoch_train_loss_list = []\n",
        "      epoch_val_loss_list = []\n",
        "      for epoch in range(params['epochs']): \n",
        "          print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
        "          train_loss = train(train_loader, net, criterion, optimizer, device, epoch+1)\n",
        "          epoch_train_loss_list.append(train_loss)\n",
        "          val_loss = test(evaluation_loader, net, criterion, device)\n",
        "          epoch_val_loss_list.append(val_loss)\n",
        "\n",
        "      print(f\"Average Testing Loss: {np.mean(epoch_train_loss_list)}\")\n",
        "      print(f\"Average Training Loss: {np.mean(epoch_val_loss_list)}\")\n",
        "      plt.plot(epoch_train_loss_list, color='blue', label=\"train\")\n",
        "      plt.plot(epoch_val_loss_list, color='olive', label=\"test\")\n",
        "      plt.ylabel('loss')\n",
        "      plt.xlabel('epoch')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "      train_loss_list.append(np.mean(epoch_train_loss_list))\n",
        "      val_loss_list.append(np.mean(epoch_val_loss_list))\n",
        "      \n",
        "      train_dataset_list.insert(fold, evaluation_data)\n",
        "\n",
        "    print('\\nFinished Training')\n",
        "    print(f'\\nAverage Testing Loss: {np.mean(train_loss_list)}')\n",
        "    print(f'\\nAverage Testing Loss: {np.mean(val_loss_list)}')\n",
        "    \n",
        "    print('\\nTesting on test set')\n",
        "    test(test_loader, net, criterion, device)\n",
        "    print('\\nGenerating Unlabeled Result')\n",
        "    result = get_result(test_loader, net, device, folder='output_test')\n",
        "\n",
        "    torch.save(net.state_dict(), './models/model_{}.pth'.format(name))\n",
        "\n",
        "    cal_AP(ap_loader, net, criterion, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fu5tQGIv_k2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fa18598-15c3-4115-ed88-5db183c1ca6c"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load train dataset start\n",
            "    from: ./starter_set/\n",
            "    range: [0, 906)\n",
            "load dataset done\n",
            "load test_dev dataset start\n",
            "    from: ./starter_set/\n",
            "    range: [0, 114)\n",
            "load dataset done\n",
            "load test_dev dataset start\n",
            "    from: ./starter_set/\n",
            "    range: [0, 114)\n",
            "load dataset done\n",
            "\n",
            "Start training\n",
            "\n",
            "Fold 1\n",
            "-----------------Epoch = 1-----------------\n",
            "[epoch 1] loss: 1.146 elapsed time 106.274\n",
            "1.226562594112597\n",
            "-----------------Epoch = 2-----------------\n",
            "[epoch 2] loss: 1.056 elapsed time 106.020\n",
            "1.1054504262773615\n",
            "-----------------Epoch = 3-----------------\n",
            "[epoch 3] loss: 1.011 elapsed time 105.722\n",
            "1.0462747843641984\n",
            "-----------------Epoch = 4-----------------\n",
            "[epoch 4] loss: 0.947 elapsed time 105.682\n",
            "1.0130121833399723\n",
            "-----------------Epoch = 5-----------------\n",
            "[epoch 5] loss: 0.911 elapsed time 106.270\n",
            "0.9607844384093034\n",
            "-----------------Epoch = 6-----------------\n",
            "[epoch 6] loss: 0.888 elapsed time 105.924\n",
            "0.929211647886979\n",
            "-----------------Epoch = 7-----------------\n",
            "[epoch 7] loss: 0.845 elapsed time 105.940\n",
            "0.9005865642898961\n",
            "-----------------Epoch = 8-----------------\n",
            "[epoch 8] loss: 0.824 elapsed time 105.628\n",
            "0.8718811053978769\n",
            "-----------------Epoch = 9-----------------\n",
            "[epoch 9] loss: 0.793 elapsed time 105.954\n",
            "0.8471277105180841\n",
            "-----------------Epoch = 10-----------------\n",
            "[epoch 10] loss: 0.764 elapsed time 106.341\n",
            "0.8250914968942341\n",
            "-----------------Epoch = 11-----------------\n",
            "[epoch 11] loss: 0.748 elapsed time 105.948\n",
            "0.8163141639609086\n",
            "-----------------Epoch = 12-----------------\n",
            "[epoch 12] loss: 0.722 elapsed time 105.698\n",
            "0.7880998567530983\n",
            "-----------------Epoch = 13-----------------\n",
            "[epoch 13] loss: 0.682 elapsed time 106.499\n",
            "0.7684090262965152\n",
            "-----------------Epoch = 14-----------------\n",
            "[epoch 14] loss: 0.663 elapsed time 105.893\n",
            "0.7548478026139108\n",
            "-----------------Epoch = 15-----------------\n",
            "[epoch 15] loss: 0.630 elapsed time 105.925\n",
            "0.7379191862909418\n",
            "-----------------Epoch = 16-----------------\n",
            "[epoch 16] loss: 0.617 elapsed time 105.865\n",
            "0.7226350872140181\n",
            "-----------------Epoch = 17-----------------\n",
            "[epoch 17] loss: 0.602 elapsed time 105.881\n",
            "0.7195321321487427\n",
            "-----------------Epoch = 18-----------------\n",
            "[epoch 18] loss: 0.597 elapsed time 104.557\n",
            "0.7051774733944943\n",
            "-----------------Epoch = 19-----------------\n",
            "[epoch 19] loss: 0.581 elapsed time 104.110\n",
            "0.6968703489554556\n",
            "-----------------Epoch = 20-----------------\n",
            "[epoch 20] loss: 0.572 elapsed time 103.927\n",
            "0.6906976950796027\n",
            "-----------------Epoch = 21-----------------\n",
            "[epoch 21] loss: 0.556 elapsed time 104.569\n",
            "0.6941888708817331\n",
            "-----------------Epoch = 22-----------------\n",
            "[epoch 22] loss: 0.546 elapsed time 103.918\n",
            "0.6898989206866214\n",
            "-----------------Epoch = 23-----------------\n",
            "[epoch 23] loss: 0.529 elapsed time 104.296\n",
            "0.6761331275889748\n",
            "-----------------Epoch = 24-----------------\n",
            "[epoch 24] loss: 0.507 elapsed time 103.762\n",
            "0.6745979252614474\n",
            "-----------------Epoch = 25-----------------\n",
            "[epoch 25] loss: 0.499 elapsed time 103.996\n",
            "0.6747418642044067\n",
            "-----------------Epoch = 26-----------------\n",
            "[epoch 26] loss: 0.481 elapsed time 104.049\n",
            "0.6617593075099745\n",
            "-----------------Epoch = 27-----------------\n",
            "[epoch 27] loss: 0.476 elapsed time 104.164\n",
            "0.6620512040037858\n",
            "-----------------Epoch = 28-----------------\n",
            "[epoch 28] loss: 0.453 elapsed time 104.030\n",
            "0.6548716300412228\n",
            "-----------------Epoch = 29-----------------\n",
            "[epoch 29] loss: 0.449 elapsed time 104.548\n",
            "0.6497945597297267\n",
            "-----------------Epoch = 30-----------------\n",
            "[epoch 30] loss: 0.433 elapsed time 104.175\n",
            "0.6430802109994387\n",
            "-----------------Epoch = 31-----------------\n",
            "[epoch 31] loss: 0.432 elapsed time 104.806\n",
            "0.6480103088052649\n",
            "-----------------Epoch = 32-----------------\n",
            "[epoch 32] loss: 0.418 elapsed time 104.683\n",
            "0.6405196268307535\n",
            "Average Testing Loss: 0.667981892824173\n",
            "Average Training Loss: 0.7842541650231731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 2\n",
            "-----------------Epoch = 1-----------------\n",
            "[epoch 1] loss: 1.143 elapsed time 105.748\n",
            "1.1995034970735248\n",
            "-----------------Epoch = 2-----------------\n",
            "[epoch 2] loss: 1.085 elapsed time 105.598\n",
            "1.127533285241378\n",
            "-----------------Epoch = 3-----------------\n",
            "[epoch 3] loss: 1.016 elapsed time 105.344\n",
            "1.0678521049650092\n",
            "-----------------Epoch = 4-----------------\n",
            "[epoch 4] loss: 0.958 elapsed time 105.149\n",
            "1.0237177139834355\n",
            "-----------------Epoch = 5-----------------\n",
            "[epoch 5] loss: 0.902 elapsed time 105.863\n",
            "0.9606991661222357\n",
            "-----------------Epoch = 6-----------------\n",
            "[epoch 6] loss: 0.872 elapsed time 105.409\n",
            "0.9189323688808241\n",
            "-----------------Epoch = 7-----------------\n",
            "[epoch 7] loss: 0.832 elapsed time 105.524\n",
            "0.887482646264528\n",
            "-----------------Epoch = 8-----------------\n",
            "[epoch 8] loss: 0.775 elapsed time 105.156\n",
            "0.8420098016136571\n",
            "-----------------Epoch = 9-----------------\n",
            "[epoch 9] loss: 0.743 elapsed time 105.721\n",
            "0.8126409524365475\n",
            "-----------------Epoch = 10-----------------\n",
            "[epoch 10] loss: 0.696 elapsed time 105.848\n",
            "0.7836913152744895\n",
            "-----------------Epoch = 11-----------------\n",
            "[epoch 11] loss: 0.675 elapsed time 105.575\n",
            "0.7652777182428461\n",
            "-----------------Epoch = 12-----------------\n",
            "[epoch 12] loss: 0.647 elapsed time 105.181\n",
            "0.7523178175876015\n",
            "-----------------Epoch = 13-----------------\n",
            "[epoch 13] loss: 0.624 elapsed time 105.823\n",
            "0.7300242154221785\n",
            "-----------------Epoch = 14-----------------\n",
            "[epoch 14] loss: 0.592 elapsed time 105.692\n",
            "0.7170887369858591\n",
            "-----------------Epoch = 15-----------------\n",
            "[epoch 15] loss: 0.580 elapsed time 105.764\n",
            "0.7095080708202562\n",
            "-----------------Epoch = 16-----------------\n",
            "[epoch 16] loss: 0.560 elapsed time 105.358\n",
            "0.7006943884648775\n",
            "-----------------Epoch = 17-----------------\n",
            "[epoch 17] loss: 0.529 elapsed time 105.795\n",
            "0.7082380934765464\n",
            "-----------------Epoch = 18-----------------\n",
            "[epoch 18] loss: 0.540 elapsed time 105.981\n",
            "0.6856433278635928\n",
            "-----------------Epoch = 19-----------------\n",
            "[epoch 19] loss: 0.484 elapsed time 105.675\n",
            "0.6853264507494474\n",
            "-----------------Epoch = 20-----------------\n",
            "[epoch 20] loss: 0.463 elapsed time 105.352\n",
            "0.6662741491669103\n",
            "-----------------Epoch = 21-----------------\n",
            "[epoch 21] loss: 0.485 elapsed time 106.112\n",
            "0.6699653173747816\n",
            "-----------------Epoch = 22-----------------\n",
            "[epoch 22] loss: 0.455 elapsed time 105.636\n",
            "0.6671686266597948\n",
            "-----------------Epoch = 23-----------------\n",
            "[epoch 23] loss: 0.428 elapsed time 105.616\n",
            "0.6530954900540804\n",
            "-----------------Epoch = 24-----------------\n",
            "[epoch 24] loss: 0.428 elapsed time 105.001\n",
            "0.6545168067279615\n",
            "-----------------Epoch = 25-----------------\n",
            "[epoch 25] loss: 0.408 elapsed time 105.644\n",
            "0.6392573180951571\n",
            "-----------------Epoch = 26-----------------\n",
            "[epoch 26] loss: 0.442 elapsed time 105.668\n",
            "0.6232038406949294\n",
            "-----------------Epoch = 27-----------------\n",
            "[epoch 27] loss: 0.402 elapsed time 105.304\n",
            "0.609947166944805\n",
            "-----------------Epoch = 28-----------------\n",
            "[epoch 28] loss: 0.369 elapsed time 105.181\n",
            "0.6199948395553389\n",
            "-----------------Epoch = 29-----------------\n",
            "[epoch 29] loss: 0.389 elapsed time 105.807\n",
            "0.6129374974652341\n",
            "-----------------Epoch = 30-----------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}