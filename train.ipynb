{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willychangx/window-segmentation/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMC5I3as16q"
      },
      "source": [
        "# Download folders. You don't need to change anything, you'll be downloading from my Google Drive.\n",
        "\n",
        "%%capture\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1gYc0PJCTlclGfhwMbBtI5p2Q2r1hCVyR\n",
        "!unzip /content/segmentation.zip -d /content\n",
        "%rm -rf /content/segmentation.zip\n",
        "\n",
        "%cd /content/segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLxmdtj9z0Xw"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rRDmq_du2Qt"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import png\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import random\n",
        "from PIL import Image\n",
        "from colormap.colors import Color, hex2rgb\n",
        "from sklearn.metrics import average_precision_score as ap_score\n",
        "from torch.utils.data import ConcatDataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from dataset import FacadeDataset\n",
        "\n",
        "N_CLASS=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuZYt4yBrHt-"
      },
      "source": [
        "# images are 256x256\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "params = {\n",
        "    'batch_size': 10,\n",
        "    'loss_function': nn.CrossEntropyLoss(),\n",
        "    'learning_rate': 1e-3,\n",
        "    'weight_decay': 1e-5,\n",
        "    'epochs': 32,\n",
        "    'percent': 0.20,\n",
        "    'fold': 1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akodRK96u_tU"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.n_class = N_CLASS\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            # nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=2)\n",
        "        )\n",
        "        self.layer56 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024, out_channels=2048, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "        )\n",
        "        self.layer65 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            # nn.Conv2d(in_channels=512, out_channels=256, kernel_size=2)\n",
        "        )\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            # nn.Conv2d(in_channels=512, out_channels=256, kernel_size=2)\n",
        "        )\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1), #, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            # nn.Conv2d(in_channels=256, out_channels=128, kernel_size=2)\n",
        "        )\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            # nn.Conv2d(in_channels=128, out_channels=64, kernel_size=2)\n",
        "        )\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), # , bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=N_CLASS, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        x1 = self.layer1(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x1) # max pool 2x2\n",
        "        x2 = self.layer2(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x2) # max pool 2x2\n",
        "        x3 = self.layer3(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x3) # max pool 2x2\n",
        "        x4 = self.layer4(x) # conv 3x3, ReLU\n",
        "        x = down_pooling(x4) # max pool 2x2\n",
        "        x = self.layer5(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x4.size()[2], x4.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        # x = down_pooling(x5)\n",
        "        # x = self.layer56(x)\n",
        "        # x = torch.cat([x5, x], dim=1)\n",
        "        # x = self.layer65(x)\n",
        "        x = torch.cat([x4, x], dim=1)\n",
        "        x = self.layer6(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x3.size()[2], x3.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        x = torch.cat([x3, x], dim=1)\n",
        "        x = self.layer7(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x2.size()[2], x2.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        x = torch.cat([x2, x], dim=1)\n",
        "        x = self.layer8(x) # conv 3x3, ReLU, up-conv 2x2\n",
        "        # crop = transforms.CenterCrop((x1.size()[2], x1.size()[3]))\n",
        "        # x = crop.forward(x)\n",
        "        x = torch.cat([x1, x], dim=1)\n",
        "        x = self.layer9(x) # conv 3x3, ReLU, conv 1x1\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7TgxpVpvres"
      },
      "source": [
        "def save_label(label, path):\n",
        "    '''\n",
        "    Function for ploting labels.\n",
        "    '''\n",
        "    colormap = [\n",
        "        '#000000',\n",
        "        '#0080FF',\n",
        "        '#80FF80',\n",
        "        '#FF8000',\n",
        "        '#FF0000',\n",
        "    ]\n",
        "    assert(np.max(label)<len(colormap))\n",
        "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
        "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
        "    with open(path, 'wb') as f:\n",
        "        w.write(f, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_vqo3uOvvz9"
      },
      "source": [
        "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
        "    '''\n",
        "    Function for training.\n",
        "    '''\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_loss_list = []\n",
        "    net = net.train()\n",
        "    for images, labels in tqdm(trainloader, disable=True):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()\n",
        "        running_loss_list.append(running_loss)\n",
        "    end = time.time()\n",
        "    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n",
        "          (epoch, running_loss, end-start))\n",
        "    print('average training loss: %.3f' % (np.mean(running_loss_list)))\n",
        "    return np.mean(running_loss_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNH-8uJVv0Yd"
      },
      "source": [
        "def test(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Function for testing.\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        for images, labels in tqdm(testloader, disable=True):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)\n",
        "            loss = criterion(output, labels)\n",
        "            losses += loss.item()\n",
        "            cnt += 1\n",
        "    print('average validation loss: %.3f' % (losses / cnt))\n",
        "    return (losses/cnt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnnDzDHVv4XN"
      },
      "source": [
        "def cal_AP(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Calculate Average Precision\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        preds = [[] for _ in range(5)]\n",
        "        heatmaps = [[] for _ in range(5)]\n",
        "        for images, labels in tqdm(testloader, disable=True):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images).cpu().numpy()\n",
        "            for c in range(5):\n",
        "                preds[c].append(output[:, c].reshape(-1))\n",
        "                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n",
        "\n",
        "        aps = []\n",
        "        for c in range(5):\n",
        "            preds[c] = np.concatenate(preds[c])\n",
        "            heatmaps[c] = np.concatenate(heatmaps[c])\n",
        "            if heatmaps[c].max() == 0:\n",
        "                ap = float('nan')\n",
        "            else:\n",
        "                ap = ap_score(heatmaps[c], preds[c])\n",
        "                aps.append(ap)\n",
        "            print(\"AP = {}\".format(ap))\n",
        "\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7c2L0vPv7Mn"
      },
      "source": [
        "def get_result(testloader, net, device, folder='output_train'):\n",
        "    result = []\n",
        "    cnt = 1\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        cnt = 0\n",
        "        for images, labels in tqdm(testloader, disable=True):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)[0].cpu().numpy()\n",
        "            c, h, w = output.shape\n",
        "            assert(c == N_CLASS)\n",
        "            y = np.zeros((h,w)).astype('uint8')\n",
        "            for i in range(N_CLASS):\n",
        "                mask = output[i]>0.5\n",
        "                y[mask] = i\n",
        "            # gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n",
        "            gt = labels.cpu().data.numpy().astype('uint8')\n",
        "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
        "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
        "            plt.imsave(\n",
        "                './{}/x{}.png'.format(folder, cnt),\n",
        "                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n",
        "\n",
        "            cnt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOrUtgVhv9R2"
      },
      "source": [
        "def main():\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    test_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=10)\n",
        "    ap_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=True)\n",
        "    ap_loader = DataLoader(ap_data, batch_size=10)\n",
        "    uh_data = FacadeDataset(flag='uh_test', dataDir='./uh_test/', data_range=(0,1), onehot=False)\n",
        "    uh_loader = DataLoader(uh_data, batch_size=1)\n",
        "\n",
        "    name = 'starter_net'\n",
        "    \n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    indexes = [i for i in range(906)]\n",
        "    random.shuffle(indexes)\n",
        "    folds = [indexes[i::int(1/params['percent'])] for i in range(int(1/params['percent']))]\n",
        "\n",
        "    print('\\nStart training')\n",
        "    for fold in range(params['fold']):\n",
        "      print(f'\\nFold {fold+1}')\n",
        "      train_data_list = folds\n",
        "\n",
        "      evaluation_data_list = train_data_list.pop(fold)\n",
        "      train_data_list = np.array(train_data_list).flatten()\n",
        "      \n",
        "      train_data = FacadeDataset(flag='train', data_range=train_data_list, onehot=False)\n",
        "      train_loader = DataLoader(train_data, batch_size=params['batch_size'])\n",
        "      \n",
        "      evaluation_data = FacadeDataset(flag='train', data_range=evaluation_data_list, onehot=False)\n",
        "      evaluation_loader = DataLoader(evaluation_data, batch_size=params['batch_size'])\n",
        "\n",
        "      evaluation_data_AP = FacadeDataset(flag='train', data_range=evaluation_data_list, onehot=True)\n",
        "      evaluation_loader_AP = DataLoader(evaluation_data_AP, batch_size=params['batch_size'])\n",
        "\n",
        "      net = Net().to(device)\n",
        "\n",
        "      criterion = params['loss_function']\n",
        "      optimizer = optim.Adam(net.parameters(), params['learning_rate'], weight_decay=params['weight_decay'])\n",
        "\n",
        "      epoch_train_loss_list = []\n",
        "      epoch_val_loss_list = []\n",
        "      for epoch in range(params['epochs']): \n",
        "          print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
        "          train_loss = train(train_loader, net, criterion, optimizer, device, epoch+1)\n",
        "          epoch_train_loss_list.append(train_loss)\n",
        "          val_loss = test(evaluation_loader, net, criterion, device)\n",
        "          epoch_val_loss_list.append(val_loss)\n",
        "          cal_AP(evaluation_loader_AP, net, criterion, device)\n",
        "\n",
        "      plt.plot(epoch_train_loss_list, color='blue', label=\"train\")\n",
        "      plt.plot(epoch_val_loss_list, color='olive', label=\"test\")\n",
        "      plt.ylabel('loss')\n",
        "      plt.xlabel('epoch')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "      train_loss_list.append(np.mean(epoch_train_loss_list))\n",
        "      val_loss_list.append(np.mean(epoch_val_loss_list))\n",
        "\n",
        "    print('\\nFinished Training')\n",
        "    print(f'\\nAverage Testing Loss: {np.mean(train_loss_list)}')\n",
        "    print(f'\\nAverage Testing Loss: {np.mean(val_loss_list)}')\n",
        "\n",
        "    print('\\nTesting on test set')\n",
        "    test(test_loader, net, criterion, device)\n",
        "    print('\\nGenerating Unlabeled Result')\n",
        "    result = get_result(test_loader, net, device, folder='output_test')\n",
        "    print('\\nPredicting on UH building image')\n",
        "    res = get_result(uh_loader, net, device, folder='output_train')\n",
        "\n",
        "    torch.save(net.state_dict(), './models/model_{}.pth'.format(name)) \n",
        "\n",
        "    cal_AP(ap_loader, net, criterion, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Fu5tQGIv_k2",
        "outputId": "2dd23f80-16cb-4f22-ffab-a7ef0fbbc971"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load test_dev dataset start\n",
            "    from: ./starter_set/\n",
            "    range: [0, 114)\n",
            "load dataset done\n",
            "load test_dev dataset start\n",
            "    from: ./starter_set/\n",
            "    range: [0, 114)\n",
            "load dataset done\n",
            "load uh_test dataset start\n",
            "    from: ./uh_test/\n",
            "    range: [0, 1)\n",
            "load dataset done\n",
            "\n",
            "Start training\n",
            "\n",
            "Fold 1\n",
            "load train dataset start\n",
            "    from: ./starter_set/\n",
            "    range: randomized, size is 724\n",
            "load dataset done\n",
            "load train dataset start\n",
            "    from: ./starter_set/\n",
            "    range: randomized, size is 182\n",
            "load dataset done\n",
            "load train dataset start\n",
            "    from: ./starter_set/\n",
            "    range: randomized, size is 182\n",
            "load dataset done\n",
            "-----------------Epoch = 1-----------------\n",
            "[epoch 1] loss: 0.894 elapsed time 107.825\n",
            "average training loss: 1.056\n",
            "average validation loss: 1.102\n",
            "AP = 0.5594857556919952\n",
            "AP = 0.7399012415032805\n",
            "AP = 0.06434519052310568\n",
            "AP = 0.673593396695781\n",
            "AP = 0.1539099360381331\n",
            "-----------------Epoch = 2-----------------\n",
            "[epoch 2] loss: 0.777 elapsed time 108.726\n",
            "average training loss: 0.866\n",
            "average validation loss: 0.920\n",
            "AP = 0.6448687208150824\n",
            "AP = 0.7814466723827845\n",
            "AP = 0.08689736311011223\n",
            "AP = 0.793749155910558\n",
            "AP = 0.2850034843951202\n",
            "-----------------Epoch = 3-----------------\n",
            "[epoch 3] loss: 0.747 elapsed time 108.645\n",
            "average training loss: 0.795\n",
            "average validation loss: 0.817\n",
            "AP = 0.6593568955765501\n",
            "AP = 0.7861132406711879\n",
            "AP = 0.14849919504210543\n",
            "AP = 0.8364729737946023\n",
            "AP = 0.5095610017219772\n",
            "-----------------Epoch = 4-----------------\n",
            "[epoch 4] loss: 0.728 elapsed time 108.545\n",
            "average training loss: 0.741\n",
            "average validation loss: 0.737\n",
            "AP = 0.7194903667913619\n",
            "AP = 0.8077895829403435\n",
            "AP = 0.1829998733212012\n",
            "AP = 0.8507476617018511\n",
            "AP = 0.638418091622428\n",
            "-----------------Epoch = 5-----------------\n",
            "[epoch 5] loss: 0.671 elapsed time 108.558\n",
            "average training loss: 0.701\n",
            "average validation loss: 0.714\n",
            "AP = 0.7386281096427222\n",
            "AP = 0.8087480410654435\n",
            "AP = 0.24198941512157848\n",
            "AP = 0.8620314080190368\n",
            "AP = 0.6505778051705834\n",
            "-----------------Epoch = 6-----------------\n",
            "[epoch 6] loss: 0.626 elapsed time 108.535\n",
            "average training loss: 0.665\n",
            "average validation loss: 0.690\n",
            "AP = 0.7343382539217295\n",
            "AP = 0.8132347291689065\n",
            "AP = 0.2496321245264436\n",
            "AP = 0.870599701897764\n",
            "AP = 0.7114517040061221\n",
            "-----------------Epoch = 7-----------------\n",
            "[epoch 7] loss: 0.601 elapsed time 108.521\n",
            "average training loss: 0.632\n",
            "average validation loss: 0.703\n",
            "AP = 0.7526462181017164\n",
            "AP = 0.8066187812517825\n",
            "AP = 0.26256928582499794\n",
            "AP = 0.8768988291354334\n",
            "AP = 0.6878134206353073\n",
            "-----------------Epoch = 8-----------------\n",
            "[epoch 8] loss: 0.570 elapsed time 108.505\n",
            "average training loss: 0.613\n",
            "average validation loss: 0.730\n",
            "AP = 0.7277679324914554\n",
            "AP = 0.8154114741732882\n",
            "AP = 0.3078056482574786\n",
            "AP = 0.8711453125441271\n",
            "AP = 0.6397448480677633\n",
            "-----------------Epoch = 9-----------------\n",
            "[epoch 9] loss: 0.535 elapsed time 108.447\n",
            "average training loss: 0.587\n",
            "average validation loss: 0.672\n",
            "AP = 0.7425230865754591\n",
            "AP = 0.8224687709994297\n",
            "AP = 0.3345795775222558\n",
            "AP = 0.8740264174696918\n",
            "AP = 0.7555850137110868\n",
            "-----------------Epoch = 10-----------------\n",
            "[epoch 10] loss: 0.514 elapsed time 108.416\n",
            "average training loss: 0.562\n",
            "average validation loss: 0.636\n",
            "AP = 0.7815345865064774\n",
            "AP = 0.8274245150885862\n",
            "AP = 0.39397368306157826\n",
            "AP = 0.8800590663824115\n",
            "AP = 0.7927929387823576\n",
            "-----------------Epoch = 11-----------------\n",
            "[epoch 11] loss: 0.482 elapsed time 108.374\n",
            "average training loss: 0.540\n",
            "average validation loss: 0.674\n",
            "AP = 0.7764822033779721\n",
            "AP = 0.8409982783333896\n",
            "AP = 0.3908504160543973\n",
            "AP = 0.8908710268303525\n",
            "AP = 0.7456324119319591\n",
            "-----------------Epoch = 12-----------------\n",
            "[epoch 12] loss: 0.461 elapsed time 108.447\n",
            "average training loss: 0.526\n",
            "average validation loss: 0.641\n",
            "AP = 0.7709242025314946\n",
            "AP = 0.8360039237110193\n",
            "AP = 0.3750080963333009\n",
            "AP = 0.8937404179129291\n",
            "AP = 0.7528826830206321\n",
            "-----------------Epoch = 13-----------------\n",
            "[epoch 13] loss: 0.444 elapsed time 108.560\n",
            "average training loss: 0.506\n",
            "average validation loss: 0.635\n",
            "AP = 0.7511705207022299\n",
            "AP = 0.8381484713982679\n",
            "AP = 0.40154891705830187\n",
            "AP = 0.8978005685994475\n",
            "AP = 0.7606145524212439\n",
            "-----------------Epoch = 14-----------------\n",
            "[epoch 14] loss: 0.410 elapsed time 108.406\n",
            "average training loss: 0.493\n",
            "average validation loss: 0.601\n",
            "AP = 0.7610724664808725\n",
            "AP = 0.8441430991847285\n",
            "AP = 0.4179045041032363\n",
            "AP = 0.9126685213123106\n",
            "AP = 0.7812137288322035\n",
            "-----------------Epoch = 15-----------------\n",
            "[epoch 15] loss: 0.414 elapsed time 108.364\n",
            "average training loss: 0.466\n",
            "average validation loss: 0.598\n",
            "AP = 0.7431053301824768\n",
            "AP = 0.8377966087732407\n",
            "AP = 0.44504375424324394\n",
            "AP = 0.9184537903228385\n",
            "AP = 0.8172254655920785\n",
            "-----------------Epoch = 16-----------------\n",
            "[epoch 16] loss: 0.389 elapsed time 108.396\n",
            "average training loss: 0.445\n",
            "average validation loss: 0.659\n",
            "AP = 0.6996796557450413\n",
            "AP = 0.8362658716530391\n",
            "AP = 0.4915564786710098\n",
            "AP = 0.9043684225260872\n",
            "AP = 0.76737202405379\n",
            "-----------------Epoch = 17-----------------\n",
            "[epoch 17] loss: 0.381 elapsed time 108.435\n",
            "average training loss: 0.427\n",
            "average validation loss: 0.556\n",
            "AP = 0.8039029819155994\n",
            "AP = 0.8563659162085967\n",
            "AP = 0.5709669201460805\n",
            "AP = 0.9256760365642563\n",
            "AP = 0.8206042690329347\n",
            "-----------------Epoch = 18-----------------\n",
            "[epoch 18] loss: 0.366 elapsed time 108.371\n",
            "average training loss: 0.413\n",
            "average validation loss: 0.556\n",
            "AP = 0.7894316604274597\n",
            "AP = 0.8629364253921669\n",
            "AP = 0.5445062317079867\n",
            "AP = 0.925120115983859\n",
            "AP = 0.8435844105478345\n",
            "-----------------Epoch = 19-----------------\n",
            "[epoch 19] loss: 0.325 elapsed time 108.461\n",
            "average training loss: 0.392\n",
            "average validation loss: 0.546\n",
            "AP = 0.802320162812936\n",
            "AP = 0.8755052201224433\n",
            "AP = 0.5504376883371991\n",
            "AP = 0.9248096471256902\n",
            "AP = 0.8484813774877631\n",
            "-----------------Epoch = 20-----------------\n",
            "[epoch 20] loss: 0.299 elapsed time 108.431\n",
            "average training loss: 0.372\n",
            "average validation loss: 0.595\n",
            "AP = 0.7874076079563072\n",
            "AP = 0.8718967345636915\n",
            "AP = 0.5565113919502158\n",
            "AP = 0.9134756330854348\n",
            "AP = 0.8102434030920658\n",
            "-----------------Epoch = 21-----------------\n",
            "[epoch 21] loss: 0.294 elapsed time 108.443\n",
            "average training loss: 0.362\n",
            "average validation loss: 0.558\n",
            "AP = 0.8228806912893594\n",
            "AP = 0.8817457765212209\n",
            "AP = 0.5834854499384208\n",
            "AP = 0.9195749360491211\n",
            "AP = 0.8182313036521417\n",
            "-----------------Epoch = 22-----------------\n",
            "[epoch 22] loss: 0.282 elapsed time 108.359\n",
            "average training loss: 0.344\n",
            "average validation loss: 0.541\n",
            "AP = 0.82297286153551\n",
            "AP = 0.8851464870333869\n",
            "AP = 0.5891432306973077\n",
            "AP = 0.9301386719217013\n",
            "AP = 0.8649037549373115\n",
            "-----------------Epoch = 23-----------------\n",
            "[epoch 23] loss: 0.252 elapsed time 108.435\n",
            "average training loss: 0.320\n",
            "average validation loss: 0.587\n",
            "AP = 0.8416762933737704\n",
            "AP = 0.8945437082312203\n",
            "AP = 0.594491197121023\n",
            "AP = 0.9226234672862585\n",
            "AP = 0.8634473800204066\n",
            "-----------------Epoch = 24-----------------\n",
            "[epoch 24] loss: 0.244 elapsed time 108.463\n",
            "average training loss: 0.308\n",
            "average validation loss: 0.590\n",
            "AP = 0.8382052428443388\n",
            "AP = 0.8907954895972299\n",
            "AP = 0.6480264444587677\n",
            "AP = 0.9270723728883127\n",
            "AP = 0.8592440531608535\n",
            "-----------------Epoch = 25-----------------\n",
            "[epoch 25] loss: 0.246 elapsed time 108.470\n",
            "average training loss: 0.294\n",
            "average validation loss: 0.540\n",
            "AP = 0.8722383955219877\n",
            "AP = 0.9024226548267833\n",
            "AP = 0.6695145490325619\n",
            "AP = 0.9355476920947388\n",
            "AP = 0.8748006841277287\n",
            "-----------------Epoch = 26-----------------\n",
            "[epoch 26] loss: 0.249 elapsed time 108.463\n",
            "average training loss: 0.280\n",
            "average validation loss: 0.474\n",
            "AP = 0.86624998863694\n",
            "AP = 0.9061703384595073\n",
            "AP = 0.6558336567895837\n",
            "AP = 0.9371191082942961\n",
            "AP = 0.8665141929081972\n",
            "-----------------Epoch = 27-----------------\n",
            "[epoch 27] loss: 0.240 elapsed time 108.467\n",
            "average training loss: 0.277\n",
            "average validation loss: 0.476\n",
            "AP = 0.8683838326358423\n",
            "AP = 0.9066138020046077\n",
            "AP = 0.6846699262416236\n",
            "AP = 0.9400191862177028\n",
            "AP = 0.8765388168601709\n",
            "-----------------Epoch = 28-----------------\n",
            "[epoch 28] loss: 0.236 elapsed time 108.289\n",
            "average training loss: 0.278\n",
            "average validation loss: 0.525\n",
            "AP = 0.8571977257612121\n",
            "AP = 0.9041545103871985\n",
            "AP = 0.6689452369924463\n",
            "AP = 0.9312005819207496\n",
            "AP = 0.838558652200635\n",
            "-----------------Epoch = 29-----------------\n",
            "[epoch 29] loss: 0.195 elapsed time 108.327\n",
            "average training loss: 0.253\n",
            "average validation loss: 0.459\n",
            "AP = 0.8858885279968455\n",
            "AP = 0.9164776142525894\n",
            "AP = 0.7541601141166134\n",
            "AP = 0.9408317005811677\n",
            "AP = 0.8857105948705879\n",
            "-----------------Epoch = 30-----------------\n",
            "[epoch 30] loss: 0.194 elapsed time 108.358\n",
            "average training loss: 0.233\n",
            "average validation loss: 0.506\n",
            "AP = 0.8617164143478669\n",
            "AP = 0.9116757712460442\n",
            "AP = 0.6815767871047554\n",
            "AP = 0.9377417378761901\n",
            "AP = 0.8711950470332962\n",
            "-----------------Epoch = 31-----------------\n",
            "[epoch 31] loss: 0.194 elapsed time 108.270\n",
            "average training loss: 0.224\n",
            "average validation loss: 0.474\n",
            "AP = 0.8652281619860706\n",
            "AP = 0.9154002188553189\n",
            "AP = 0.7535232920724633\n",
            "AP = 0.9440806080553558\n",
            "AP = 0.8860003675135333\n",
            "-----------------Epoch = 32-----------------\n",
            "[epoch 32] loss: 0.200 elapsed time 108.289\n",
            "average training loss: 0.224\n",
            "average validation loss: 0.494\n",
            "AP = 0.8593364209494934\n",
            "AP = 0.9166435852676184\n",
            "AP = 0.7173238470952145\n",
            "AP = 0.9364291670615552\n",
            "AP = 0.876536522476539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yNZ//A8c+VJZKYsRNEib1FiqiirV2jWrt91OygOp/y69Cn43m6q5NSahVVWqW1ldqSIPaILWaMICH7+v1xHaRERHJO7iTn+369zivn3Oc+9/29X4d8c1/jeymtNUIIIZyXi9UBCCGEsJYkAiGEcHKSCIQQwslJIhBCCCcniUAIIZycm9UB3KsSJUrogIAAq8MQQog8ZfPmzee01iXTey/PJYKAgADCw8OtDkMIIfIUpdTRO70nTUNCCOHkJBEIIYSTk0QghBBOLs/1EQghRFYkJSURFRVFfHy81aE4lKenJ/7+/ri7u2f6M5IIhBBOISoqikKFChEQEIBSyupwHEJrzfnz54mKiqJSpUqZ/pw0DQkhnEJ8fDy+vr75NgkAKKXw9fW957seSQRCCKeRn5PAdVm5RqdJBMePr2f58lFI2W0hhPgnp0kEp05tZd26D7l06Y5zKoQQwmFiYmL47rvv7vlzHTp0ICYmxgER3eQ0iaBixQcAOHp0jcWRCCGc0Z0SQXJycoafW7hwIUWLFnVUWIATJYJSpWrj6VmUY8ckEQghct7IkSM5ePAg9evXp3HjxjzwwAN07tyZmjVrAtC1a1caNWpErVq1GD9+/I3PBQQEcO7cOY4cOUKNGjUYPHgwtWrVok2bNly7ds0usTnN8FGlXKhQoTlHj662OhQhhMVefBEiIux7zPr1YcyYO7//4YcfsnPnTiIiIli1ahUdO3Zk586dN4Z5Tpo0ieLFi3Pt2jUaN25M9+7d8fX1/ccxIiMjmTlzJhMmTKBHjx7MnTuXfv36ZTt2p7kjAKhQ4QHOn99HXNxZq0MRQji54ODgf4z1/+qrr6hXrx5NmjTh+PHjREZG3vaZSpUqUb9+fQAaNWrEkSNH7BKL09wRgEkEAMeOraVGjccsjkYIYZWM/nLPKd7e3jeer1q1iuXLl7Nhwwa8vLxo2bJlunMBChQocOO5q6ur3ZqGnOqOoFy5Rri5FZQOYyFEjitUqBBXrlxJ971Lly5RrFgxvLy82Lt3Lxs3bszR2JzqjsDV1QN//yYcOyb9BEKInOXr60tISAi1a9emYMGClC5d+sZ77dq1Y9y4cdSoUYNq1arRpEmTHI3NqRIBmOahNWveJyHhMgUKFLY6HCGEE5kxY0a62wsUKMCiRYvSfe96P0CJEiXYuXPnje2vvvqq3eJyqqahs2fNfAKtUzl+fIPV4QghRK7gNInggw/Azw+KF2+Ki4ubDCMVQggbp0kE9epBcjJs2+ZN2bINZWKZEELYOE0iaNbM/Fy3zvQTnDgRSnJygrVBCSFELuA0iaB4cahR42YiSElJ4OTJMKvDEkIIyzlNIgAICYENG8DfvzmA9BMIIQROmAguXoRjx3wpWbKW9BMIIXJMVstQA4wZM4arV6/aOaKbnCoR3NpPcPz4elJTU6wNSgjhFCQR5BKBgVCypEkEFSs+QELCZc6c2W51WEIIJ5C2DPVrr73GJ598QuPGjalbty6jR48GIC4ujo4dO1KvXj1q167Nzz//zFdffcXJkydp1aoVrVq1ckhsTjWzWClzV7BuHXz55fWFalZTtmwDiyMTQuSkxYtf5PRp+9ahLlOmPu3a3bmaXdoy1EuXLmXOnDmEhoaitaZz586sXr2a6OhoypUrx59//gmYGkRFihTh888/Z+XKlZQoUcKuMV/nVHcEYPoJDhyA+PjyFC0aIP0EQogct3TpUpYuXUqDBg1o2LAhe/fuJTIykjp16rBs2TJef/111qxZQ5EiRXIkHofdESilJgGdgLNa69rpvK+AL4EOwFWgv9Z6i6PiuS4kxPxcv970Exw8uAStNSYcIYQzyOgv95ygtWbUqFEMHTr0tve2bNnCwoULefPNN3nooYd4++23HR6PI+8IJgPtMni/PRBoewwBxjowlhsaNYICBW52GMfFneXChdsXgBBCCHtKW4a6bdu2TJo0idjYWABOnDjB2bNnOXnyJF5eXvTr14/XXnuNLVu23PZZR3DYHYHWerVSKiCDXboAU7XWGtiolCqqlCqrtT7lqJjAJIGgIJMIRo5sAZh+Al/fqo48rRDCyaUtQ92+fXv69OlD06ZNAfDx8WH69OkcOHCA1157DRcXF9zd3Rk71vx9PGTIENq1a0e5cuVYuXKl3WOzsrPYDzie5nWUbdttiUApNQRz10CFChWyfeKQEPjiC/Dyqoq3dymOHVtDw4aDsn1cIYTIyK1lqEeMGPGP15UrV6Zt27a3fW748OEMHz7cYXHlic5irfV4rXWQ1jqoZMmS2T5eSAgkJcHmzcq2oL10GAshnJeVieAEUD7Na3/bNof758SyFsTEHOby5aicOLUQQuQ6ViaC+cBTymgCXHJ0/8B1JUpAtWo3J5YBclcghBMwXZL5W1au0WGJQCk1E9gAVFNKRSmlBiqlnlFKPWPbZSFwCDgATACec1Qs6WnWzAwhLVmyHh4ehWQ+gRD5nKenJ+fPn8/XyUBrzfnz5/H09Lynzzly1FDvu7yvgecddf67CQmBH3+EyEhXypdvJolAiHzO39+fqKgooqOjrQ7FoTw9PfH397+nzzhViYm00k4sq1q1BX/99QbXrl2gYMHi1gYmhHAId3d3KlWqZHUYuVKeGDXkCNWqga/vzYllAMeOrbU4KiGEyHlOmwjSFqDz82uMq6uHdBgLIZyS0yYCMM1D+/fDxYue+PkFSz+BEMIpOX0igOsF6Fpw6tRmEhPjrA1KCCFymFMngqAg8PC4OZ8gNTWZqKiNVoclhBA5yqkTgaenqUa6bh2UL98MpVykeUgI4XScOhGAaR4KDwetC1O6dD1JBEIIpyOJIAQSE2HzZqhYsQXHj28gJSXR6rCEECLHOH0i+GcBugdITr7GqVMOXyhNCCFyDadPBKVKQZUq1xNBc0AK0AkhnIvTJwIwzUPr14O3d2l8fatKP4EQwqlIIsAkgnPnzOSySpUe5tCh5Vy7dtHqsIQQIkdIIuDmxLJ16yAoaCjJydfYunWStUEJIUQOkUQAVK8OxYqZ5qHSpetSsWILwsK+JTU1xerQhBDC4SQRAC4uNwvQATRuPIyYmMNERi60NjAhhMgBkghsQkJg7144fx6qV+9KoUJ+hIZ+bXVYQgjhcJIIbNIWoHN1dSco6FkOHVrGuXN7rQ1MCCEcTBKBTePG4O5+s3moUaPBuLp6EBr6jbWBCSGEg0kisClYEBo2vJkIvL1LUbt2L7Ztm0JCwmVrgxNCCAeSRJBGSAiEhUFCgnkdHDycxMRYIiImWxqXEEI4kiSCNJo1M0lgi63UULlyQfj7NyE09Bu0TrU2OCGEcBBJBGmknVh2XXDwcC5ciOTgwaXWBCWEEA4miSCNMmXgvvv+mQhq1nwcH58yMpRUCJFvSSK4RevWsGQJHD1qXru6etCo0VAiIxdx4cIBa4MTQggHkERwizffBKVgxIib2xo1GoqLiyuhod9aF5gQQjiIJIJbVKwIb78Nv/8OCxaYbYUKlaVmzSeIiJhEYmKstQEKIYSdSSJIx0svQc2aMHw4XL1qtgUHDych4TLbtk2zNjghhLAzSQTp8PCAsWNNP8H775tt/v5NKFu2EWFh36C1tjZAIYSwI0kEd9CiBfzrX/Dpp7BnDyilCA4eTnT0bg4f/svq8IQQwm4kEWTgk0/Axweeew60htq1e+LlVUKGkgoh8hVJBBkoWRL+9z9YtQqmTwc3N08aNhzC/v0LiIk5YnV4QghhF5II7mLwYLj/fnjlFbh4ERo3fhZQhIV9Z3VoQghhF5II7sLFxXQcnz8Pb7wBhQv7U6NGN7Zs+YGkpKtWhyeEENkmiSATGjQwQ0nHjYPQULOUZXz8RXbsmGF1aEIIkW2SCDLp3XehbFl49lnw929BmTL1WbfuI1JSkqwOTQghssWhiUAp1U4ptU8pdUApNTKd9ysopVYqpbYqpbYrpTo4Mp7sKFwYvvjClKgeO1bRqtX7XLhwgM2bx1sdmhBCZIvDEoFSyhX4FmgP1AR6K6Vq3rLbm8BsrXUDoBeQq3tgn3gCHnnE1CPy8elAQEBL/v77P7KCmRAiT3PkHUEwcEBrfUhrnQjMArrcso8GCtueFwFOOjCebFMKvv3WLF7z6quKhx/+mKtXo1m//lOrQxNCiCxzZCLwA46neR1l25bWO0A/pVQUsBAYnt6BlFJDlFLhSqnw6OhoR8SaaYGBMHIkzJwJe/Y0platHmzY8BlXrpyyNC4hhMgqqzuLewOTtdb+QAdgmlLqtpi01uO11kFa66CSJUvmeJC3GjnSJIT+/aFOnf+SkpLEqlXvWB2WEEJkiSMTwQmgfJrX/rZtaQ0EZgNorTcAnkAJB8ZkF56e8MsvZoLZwIGVadDgGbZu/YHo6D1WhyaEEPfMkYkgDAhUSlVSSnlgOoPn37LPMeAhAKVUDUwisLbtJ5Pq1YMffzTLWi5c+Bbu7t6sWDHK6rCEEOKeOSwRaK2TgWHAEmAPZnTQLqXUu0qpzrbdXgEGK6W2ATOB/joP1Xju0QNGjYKxY0vi4fE6+/b9zrFja60OSwgh7onKQ793AQgKCtLh4eFWh3FDSgo8+iisXHmV0aMDKVmyAgMGrEcpZXVoQghxg1Jqs9Y6KL33rO4szvNcXWHGDKhQwYvFi/9DVNRG9u79zeqwhBAi0yQR2EHRojBvHmzd2p8rV2qybNlIKT0hhMgzJBHYSY0aMG2aGwsWfMjFi5Fs2fKD1SEJIUSmSCKwo86doW/fThw50oJFi94hIeGK1SEJIcRdSSKwszffVCQlfYzWZ/npp8+sDkcIIe5KEoGdmYVs7uf48Sc4ePBTdu06bXVIQgiRIUkEDlCoEDz//H9xdU3g44//Q1yc1REJIcSdSSJwkAYNquDn9wwBARPo2XMbl6VStRAil5JE4ED9+r2Fm1thGjZszPDhL3DkyBmrQxJCiNtIInAgb+9SjBixnTJl+hMQ8B0//FCZX399k/j4S1aHRkLCZZYte501a/5ndShCCIu5WR1Afle4sD/PPTeepUtfZfLkt3F3/4C9e7/jwQdHEhw8DHd3rxyNR2vN7t1zWLx4BLGxZg2FYsXuo3btnjkahxAi95A7ghzSpk1VRo2axZw5W4iMvJ/ly1/n668DCQ//PsdmIV+8eIgZMzoyZ04PfHzKMGDAOsqXb8aCBYM5fz4yR2IQQuQ+UnQuhx0+DG3agIvLaoYMGUVs7HqKF69Cy5bvUrt2T9JZlyfbUlISWb/+U1avfg8XF3dat36fxo2fw8XFjUuXjvP99/UpXLg8AwduwN29oN3PL4SwnhSdy0UqVYK1a8HbuwUjR66lXLkFuLkV5Ndf+zBhQjBHjvxt1/MdOfI348bV56+/3qBq1U48//we7r//BVxcTKtgkSLl6dZtGmfObGPJkpfsem4hRN4gicACpUvDypUQEqIYOrQTyckRdO06lbi4M0yZ0pJZs7pw7ty+bJ0jLi6aefP6M2VKS5KTr9Gnz5888cQvFC5867LREBjYgZCQ19m8+Xt27JiZrfMKIfIeaRqyUHw89OoFv/8Ob78Nb7xxjU2bxrB27f9ISrpKUNAzPPjgaLy9M7dOs9apnDwZzr59CwgP/46EhMs0a/YaLVq8eddO6ZSUJKZMacWZM9sYPDicEiWq2eMShRC5REZNQ5IILJacDEOGmGUv+/eHceMgOfksq1a9w+bN4/Hw8KZ58//j/vtfSLf9PjExloMHl7F//wIiI/8kLu4sSrlw330P06bN55QqVSvTsVy+HMW4cfUpVKgcgwZtkv4CIfIRSQS5nNbwn/+YR/Pm8OuvULIkREfvYfny19m/fwFFilSgdev/UqdOby5dOsb+/X+wf/8fHDmykpSURAoUKEJgYHsCAztRpUo7vLx8sxRLZOQiZszoQIMGg+jceYKdr1QIYRVJBHnEzz+bu4LSpWHBAqhTx2w/fPgvli59ldOnt+LlVZKrV6MB8PWtSmBgJ6pVe5Ty5UNwdXW3SxwrVvwfa9f+j27dplG3bj+7HFMIYa1sJwKl1AjgR+AK8APQABiptV5qz0AzIz8nAoCwMOjSBa5cMUtgPvqo2a51Ktu3/8S+fb9TvnwzqlbthK9vVYfEkJqazJQprTl1ajODB4dTsmQNh5xHCJFz7JEItmmt6yml2gJDgbeAaVrrhvYN9e7yeyIAOHHCJIMtW+Cjj+DVV0GpnI3h8uUTfP99A3x8Stv6C3J2BrQQwr7sMY/g+q+hDpgEsCvNNmFnfn6wejU8/jj8+98wYAAkJORsDIUL+/HYY9M5e3YXCxcOs+uxr127aNfjCSGyJ7OJYLNSaikmESxRShUCUh0XlvDyglmzYPRomDwZHn4Yzp7N2RgqV27DAw/8HxERPxIa+k22j6d1KkuXvsbHHxdn0aIXSE7O4ewmhEhXZhPBQGAk0FhrfRVwB552WFQCMKudvfOOSQjh4RAcDDt25GwMLVu+Q2BgRxYtGs6SJa+QmpqSpeMkJ8czd25vNmz4FH//poSGfs2PPzbn4sXDdo5YCHGvMpsImgL7tNYxSql+wJuA9bWUnUTPnqapKDERmjWDmTk4+dfFxY1evebRuPEwNm78nFmzOpOQcG+r7Fy7doFp09qwa9dsHnnkEwYMWEfPnr9x/nwk33/fgD17fnNQ9EKIzMhsIhgLXFVK1QNeAQ4CUx0WlbhN48ZmRFG9etCnDwweDFev5sy5XVzc6NDhazp2HMuBA0uYOLEZFy8eytRnY2KOMGlSCCdObKJ791k0a/YqSimqV+/K0KFb8fUNZPbsx1i8+EVSUhIdfCX2ERd3lgULhnDp0jGrQxHCLjKbCJK1GV7UBfhGa/0tUMhxYYn0+PmZGkWjRsEPP8D998OePTl3/qCgZ3jyyaVcuXKSCROCOXp0dYb7nzy5mR9+aEJs7GmefHLZbWseFCtWiaefXsv9949g06Yv+fHHB4iJOeLAK8g+rTXz5vVny5YJrFnzX6vDEcIuMpsIriilRgFPAn8qUyvZPrOXxD1xd4f//hcWL4YzZyAoCKZMybnzV6rUmkGDNuHlVYKpUx9my5aJ6e4XGbmQyZNb4ObmyYAB66lYsUW6+7m5FaBduzH06DGXc+f28f33Ddi793dHXkK2hIZ+zYEDiyhSpCLbt08jPj7G6pCEyLbMJoKeQAIwQGt9GvAHPnFYVOKu2raFiAjTgdy/v3nExeXMuX19Axk0aCMBAS1ZsGDQbZ3ImzePZ+bMzpQoUZ2BAzdkakJajRqPMXToFooVq8zPP3dlyZKXc11T0Zkz21m27N9UrdqJnj1/JSnpKlu3/mh1WEJkW6ZLTCilSgONbS9DtdY5PJjRcIYJZfciJQXefRfeew+qVYPZs2+WpnC01NRkFi9+ibCwbwgM7MBjj81g3bqPWbv2v1Sp0p4nnpiNh4fPPR0zOTmBpUtfJSzsG0qWrImfXxOKFbuP4sUrU6xYZYoVu4+CBYujcniGXVLSNSZMCOLatQs888x2vL1LMmlSc2JjTzN8+H6HLCgkhD3ZY2ZxD8wdwCrMRLIHgNe01nPsGGemSCJI319/Qd++EBMDX38NAwfm3Gzk8PBxLFw4jAIFChEfH0ODBoPo1GnsjcVvsmL37rls2jSGCxcOEBt7+h/vFShQ5B/JISCgFVWqtM3uZWRo4cJhhIV9S79+S6hcuQ0AO3f+zNy5vejd+w+qVu3o0PMLkV12KTEBPHL9LkApVRJYrrWuZ9dIM0ESwZ2dOQP9+sHy5fDYY/DWW1C/fs6c+/Dhv5g/fyANGw6mefNRdv2LPTExjpiYw1y4cJCLFw9x8WLan4dJTU2iSZOXePjhj+xWeC+tffsWMGtWZ5o0eZm2bT+7sT0lJYkvvwygVKk69Ou32O7nFcKe7JEIdmit66R57QJsS7stp0giyFhqqqlP9MEHps/gwQfhxRdN8TpXV6ujs7+UlESWLn2N0NCvqFixBY8//jM+PmXsdvwrV04xblxdChf2Z+DAjbi5FfjH+3///R6rVr3N88/vlcV8RK5mj1pDi5VSS5RS/ZVS/YE/gYX2ClDYj4uLGV4aFQWffgpHjkC3bhAYCF98AZfy2TRAV1cP2rf/ksce+4kTJ8IYP74Rx4+vt8uxtU5l3rx/kZgYR/fuM29LAgCNGg3B1dWDsLBv7XJOIayQqUSgtX4NGA/UtT3Ga61fd2RgInuKFoVXXoEDB2DOHPD3h5dfNj9HjDDb85M6dfowaNBG3NwKMnnyg4SGfkN219rYsOELDh1aRrt2YyhRonq6+/j4lKZWrR5EREwmIeFKts4nhFUyPdRBaz1Xa/2y7SE1AfIINzfo3t2UqAgPN3cHY8dC1arQuTOsW2d1hPZTunRdhgwJp0qV9ixaNJx5854iKSlr069PndrKihWjqF69Gw0bDs5w3+Dg4SQmXmHbthyc0CGEHWWYCJRSV5RSl9N5XFFK3bXgjFKqnVJqn1LqgFJq5B326aGU2q2U2qWUmpHVCxF316gRTJ0KR4+ajuSNG83SmH36mDUQ8gNPz6L06jWPVq3eY/v2n5g4sSkXLhy8p2MkJsYxd25vvL1L8eijE+7a8e3nF4yfX7DtLkSK8oq8J8NEoLUupLUunM6jkNa6cEafVUq5At8C7YGaQG+lVM1b9gkERgEhWutawIvZuhqRKWXLmvWRjxyBt982ayRXqwYffpjz6x44glIutGjxJn37LuTSpeNMmBDE/v1/ZvrzS5a8zPnz++nWbWqm134ODh7O+fP7OHRoeVbDFsIyDluzWCnVFHhHa93W9noUgNb6f2n2+RjYr7X+IbPHlVFD9nf4sOk/mDfPdCqPGQMdOlgdlX1cvHiY2bO7c/r0VipXboO3dyk8PYtTsKB5eHn53nhesGBxTpwI49df+xAS8joPP/xhps+TnJzAmDEV8PMLpnfvBQ68IiGyJqNRQ1mf8XN3fsDxNK+jgPtv2acqgFJqHeCKSRy3DchWSg0BhgBUqFDBIcE6s0qV4LffYMkSeOEF6NjRDDf94guoXNnq6LKnWLFKDBiwjhUr/o/jx9dy4cIBrl49T0LCnYdPlSsXRKtW797TedzcCtCo0VBWr36fixcPUazYfdkNPctOn47Ax6eMXYfRivzNkXcEjwPttNaDbK+fBO7XWg9Ls88fQBLQA1O/aDVQR2t9x0peckfgWImJ8OWXpmxFUhK89poZjuqVz5YsTk1NJj4+hqtXz3Pt2gXb4zyJibHUqNEdH5/S93zMK1dOMmZMRYKDX/jHxLOcdODAYmbM6ISXVwl6956Pn1+wJXGkJzk5gfj4GDw9i6Y7FFc4llV3BCeA8mle+9u2pRUFbNJaJwGHlVL7gUAgzIFxiQx4eJhf/n37wuuvw/vvm+qmn31m1lDO4RI/DuPi4oaXVwm8vErY7ZiFCpWjRo3uRERMolWrd/Hw8LbbsTPj5MnNzJ79OKVK1SIh4QqTJz9It27TqFnzcYefOybmKFu2TLDdbcUQH3/7Izk5HoDChcszYMA6ihQpf5ejipziyEpZYUCgUqqSUsoD6AXMv2WfeUBLAKVUCUxTUeZWPBEOVa4cTJsGa9eCry/06AEPPQS7dlkdWe4WHDyc+PgYtm+fnqPnvXjxEDNmdMDLqwR9+y5m0KBNlC3bkF9+eYI1a/6X7TkVGYmJOcrkyS1Yu/ZD9uyZy8mTm7l69TwFChSmdOm6VK3ameDgF2jd+r+0bfsFCQmX+Omn9lLCOxdxWNMQgFKqAzAG0/4/SWv9gVLqXSBcaz1fmXF5nwHtgBTgA631rIyOKU1DOS8lBcaPhzffNDOThw0zaykXLWp1ZLmP1prx4xuRkpLIs8/uyJEqqXFx0UyaFMK1a+cZMGDdjclvycnxzJ8/kB07ZlCv3r949NHxuLp62PXcV66cYvLkFly9eo6nnvqLsmUb3PUzhw//xfTp7ahQIYS+fRdLM1EOsUeJiSzRWi/UWlfVWlfWWn9g2/a21nq+7bm2TVCrqbWuc7ckIKzh6grPPgv795slMr/6ygw3nTTJ1DYSNymlCA4eTnT0Lo4e/dvh50tMjGPmzE5cvnycXr3m/2MGtJubJ926TefBB99h27YpTJvWhqtXz9vt3FevnmPatIe5cuUUffsuylQSALO4UZcukzhyZBXz5w+QuRe5gBRRF5nm62tmJYeHQ5UqptR106YQGmp1ZLlL7dq9KFjQl9DQrx16ntTUZObO7cXJk+F07z6TChVCbttHKUXLlqPp1m06UVEbmDixKefPR2b73PHxMUyb1oaLFw/Rp88f+Ps3uafP163bj9at/8uOHTNYseKNbMcjskcSgbhnDRuavoOpU+HYMbN28sCBcNaSpYpyH3f3gjRsOJi9e+c5bIF7rTV//vkc+/f/Qfv231C9etcM969bty9PPfUX8fEXmTixCUeOZP1uJTExlhkzOnL27E569PiVgICWWTpO8+YjadRoKOvWfUhY2NgsxyOyTxKByBKl4MknYd8+ePVVkxSqVjXrKV++a/GR/K9x42cBHPYLbvXq99myZQLNm4+6ca67qVAhhEGDNuHtXYpp0x4hImLyPZ83Kekas2Z1ISpqE48/PovAwPb3fIzrlFJ06PANVat2YtGiYezbd+tYEpFTHNpZ7AjSWZw77d1rEsKff0KxYvDSS2ZyWpEiVkdmndmzu3Po0AqqVGmLq6sHLi7uaX7+83nBgr74+QVTpky9u3bobt06ifnzB1Kv3lN06TL5njuk4+NjmD37cQ4fXkGlSg/RoMEAqlfvhrt7wQw/l5KSyM8/P0Zk5EK6dZtK3br97um8d5KYGMeUKa04e3Yn//rXSvz9b513Kuwh2wvT5CaSCHK38HAzGW3BAjOq6MUXTdlrZxxhdPLkZhYsGERS0lVSUpJISUkkNTXptudw8/+gq2sBypVrhJ9fE/z9zaNwYf8bvxXqMxoAABciSURBVOwjIxcyc2Zn7rvvIXr3/iPLK7KlpCSxfv2nbNkynpiYI3h6FqV27T40bDiQsmUb3ra/6Y/oze7dc+jYcRxBQUOzdN47iY09w6RJzUhIuMLAgespXryKXY8vJBEIC2zZYhLC77+bu4IRI0xSKFbM6shyF601Wqdw5copTpzYRFTURqKiNnLyZDgpKaYCYKFC5fD3b0KpUnVZv/5jfH2r0b//3xQoUMgO50/l8OGVRERMYvfuuaSkJFCmTH3q1x9AnTp98PLyRetUfv/9abZtm0qbNp/TtOlL2T5ves6f38/Eic0oWLAYAwasx9u7pEPO46wkEQjLRESYhPDbb1C4sGkueuklKF7c6shyt5SURM6c2X4jMURFbeTixYMULVqJgQPXO6SO0LVrF9m5cyZbt07k1KktuLp6UL16N1xc3Nix4ydatnyXBx98y+7nTev48fVMnfoQZcrU56mnVuDuns9qm1hIEoGw3LZt8N57MHcueHtDp07Qtaupclo4w4Lm4rqrV89RoEBhu08KS8/p0xFs3TqJ7dunEx9/kZCQ13noof/lyAS5PXt+Y/bs7tSp04fHHsvZGdr5mSQCkWvs2GEmpM2fb4aburub0hVdu5oV08qWtTpCkVZycjxnz+6ibNmGOZIErvv773dZtWo0PXvOo3r1Ljl23vxMEoHIdVJSzApp8+aZZqODtkXEmjQxSaFrVzN7WTinlJQkfvghmNjY0zz33C4KFpS2xOyyrMSEEHfi6gohIfDJJxAZCTt3mkqnyckwciRUrw516sDEiflj1TRxb1xd3enS5UeuXj3HkiWO6Zy+VVzcWbZunURqanKOnC83kUQgLKcU1KoFb7wBYWFmtvI335hmo0GD4L77TMKQiWrOpUyZ+jRvPopt26be01KjWREff4lp09owf/5ANmz43KHnyo0kEYhcp3x5eP552LwZli6FGjXg3/+GChXMIjmnT1sdocgpLVq8SalStfnjj6HEx995VbnsSE5O4OefuxIdvYty5RqzcuXbREfvcci5citJBCLXUgoeeQSWLzd3Cm3awMcfQ0AADB1qmpRE/ubq6kHnzpOIjT3F0qWv2P34qakp/Pbbkxw5soouXSbTu/cCPDy8+f33p0lNTbH7+XIrSQQiTwgKgtmzTW2j/v3NqmnVqsETT8CaNabzWeRPfn6NadbsNbZuncjBg0vtdlytNYsXv8ju3b/Qps1n1K3bFx+f0rRv/w0nTmzKdhPRmTPbOXEib5TmlUQg8pQqVWDcODhyxHQqL1sGLVpA6dLQrx/MnAkXLlgdpbC3li3foUSJ6ixYMJiEhCt2Oebatf8jLOwbmjZ9laZNX76xvXbtXlSv3o2VK9/KchPRiROhTJzYjB9+aMJff72V6zugJRGIPKlMGVPp9PhxmDXLTExbsgT69IGSJeGBB+DDD828hTw2Qlqkw83Nk86dJ3Hp0nGWLft3to+3ZctE/vrrDerW7ccjj3z0j/eUUnTs+F2Wm4iio/fw00/t8fYuRb16T7JmzftMmdKay5ejsh23o0giEHlaoULQs6cpg336NGzYAP/3fxAXZzqW69Y1fQrPPmv6GUTeVb58U5o0eYnNm8dx+PBfWT7Ovn0L+OOPIVSu3JbOnSeh1O2/Bn18ymSpiSgm5ijTpj2Ci4s7Tz65jK5dp9Ct23ROn97KuHH12b//jyzFfObMDubN68/Jk5uz9Pm7kUQg8g1XVzMh7b33TNG7EydgwgSzkM60aWYBneHD4Yp9WhaEBVq3fo/ixaswf/4gEhNj7/nzx4+vZ86cHpQt24gePeZkWL01bRPRuXN773rsuLhopk9vQ2JiLP36LaF48cqAWRRoyJDNFClSnpkzH2XJkpdJSUm86/G01hw6tILp09sxblxddu+eQ3T07sxf7D2QmcXCKVy+bOYpfPst+PmZn507Wx2VyIqjR9cwefKDBAcPo337rzL9uejo3Uya1BwvrxIMGLAuU9VNY2NP8913tfD1rcrTT6/FxcU13f0SEi4zZUproqN38+STS6lQoflt+yQnx7N06WuEhX1DuXJBdO8+60aySCslJYldu2azYcOnnD4dgY9PGYKDXyAoaGi2ZljLzGLh9AoXhq+/hvXrzdoIXbrA44/DqVNWRybuVcWKDxAcPIzQ0K85enRNpj5z+XIU06e3xc2tAP36Lcl0ievrTURRURvZuPGLdPdJTo5n1qyunDmzjR495qSbBMD0c3To8DU9evzKhQsHGD++Ibt2zb7xfkLCZdav/4yvvrqP337rR3JyAp07T2TEiCM88MAoh5bZkDsC4XSSkuDTT+E//wFPT/joIxg8GFzkz6I8IzExjrFj6+Di4kqvXvNJSrpKQsLlOz4OHVpGbOxpnn56NWXK1L+nc2mtmT37MSIjF/HMMxGUKFH9xnupqcn88ssT7N07j27dplO3bt9MHTMm5ihz5/YiKmojDRsOxtOzKJs3f09CwmUCAlrSrNlrVKnSLt3+i6ySonNCpCMy0kxMW7kSmjeH8ePNLGaRNxw+vJKpU1tnuI+LixsFChTB27sUHTt+R0BAyyydK70mIq018+cPJCLiR9q1+5L773/hno6ZkpLEypVvsW7dRyjlSq1aT9C06SuUK5fu7+psk0QgxB1oDZMnwyuvQGysGXE0cqS5UxC539Gja7h06RgFChRO51EIV9cCdiufvWPHDH79tS+PPPIJzZq9yrJl/2b9+k9o0eJtWrX6T5aPGx29B3d3L4oWrWiXOO9EEoEQd3H2rFlKc+ZMMznthRfMkFNZWlNcl7aJqFGjIYSGfk1Q0HN06PBNjq7VkFXSWSzEXZQqBTNmmGai+vXNCKPy5eHll001VCHMRLOxeHh4Exr6NbVr96JDh6/zRBK4G0kEQqTRsiUsXmzWWu7a1aymVrkyPPkkbN9udXTCaj4+ZejefRZNmrxE165T7NqZayVpGhIiA0ePwpgxZmJaXBy0bWtKYrdqZaqjCpFXSNOQEFlUsSJ88YWpafTBB7B1q1ljuXFjmD5dVk8T+YMkAiEyoVgxM6Lo6FEzzDQ21jQXVawIo0fLxDSRt0kiEOIeeHqayWe7d5u+hKAgePdds3panz6wcaNUOxV5jyQCIbLAxcX0F/zxB+zfb5bW/PNPaNrUFLebNk2ajUTeIYlAiGwKDDQdylFR8M03psDdU0+Zu4S33oJdu+QuQeRukgiEsJNChcydwe7dZpGc4GDTwVy7tild8cYbpjy2JAWR20giEMLOXFygTRtYsMCsiXC99PWHH0KjRmZewquvmv6E1FSroxVC5hEIkWPOnYPff4e5c2H5clMF1c8PHnsMevUy/QsyN0E4imXzCJRS7ZRS+5RSB5RSIzPYr7tSSiulHFN2T4hcoEQJGDgQFi40tY2mTjWjjiZMgJAQUwF1wQK5SxA5z2GJQCnlCnwLtAdqAr2VUjXT2a8QMALY5KhYhMhtihY18xDmzYPoaNPJfOKEWTWtbl0z6igpyeoohbNw5B1BMHBAa31Ia50IzAK6pLPfe8BHQLwDYxEi1/LxMZ3MkZEmAYAZdRQYaBLE1avWxifyP0cmAj/geJrXUbZtNyilGgLltdZ/ZnQgpdQQpVS4Uio8Ojra/pEKkQu4u0O/fqa43YIFpv9g+HAICDCjjy5etDpCkV9ZNmpImbJ9nwOv3G1frfV4rXWQ1jqoZMnMrTUqRF7l4gKdOsG6dbB6talr9OabZl7Cq6+aukdC2JMjE8EJoHya1/62bdcVAmoDq5RSR4AmwHzpMBbipgceMDOWIyLg0UfNxLX77oO+fc2cBCHswZGJIAwIVEpVUkp5AL2A+dff1Fpf0lqX0FoHaK0DgI1AZ621jA0V4hb16pmFcw4eNM1F8+ebOQmtW5tEISONRHY4LBForZOBYcASYA8wW2u9Syn1rlKqs6POK0R+VrEifP65aR76+GNT56hTJ6hVC374AeJlyIXIAplQJkQelpQEs2fDZ5+ZtRJKlTIjkPr1g0qVZIKauEkWphEin3J3N/0FmzfDihVmgtro0aaMhZ8f9OhhltvcsgWSk62OVuRWblYHIITIPqVMf0Hr1qa5aMUKWLvWPH75xezj4wNNmpgZzM2bm3LZPj7Wxi1yB2kaEiKfO3bMDEVdt84khu3bTQVUV1czk3n4cGjZUpqR8ruMmobkjkCIfK5CBfPo3du8vnQJNmwwhe8mT4bffjOdzcOGmb4FuUtwPtJHIISTKVIE2rWDTz81o49+/BEKFIBnnwV/f3jpJThwwOooRU6SRCCEEytYEPr3h/BwWL8eOnQw9Y0CA83zRYtkjoIzkEQghEApsx7CjBmmT+Gdd8xw1A4doFo1s10SQv4liUAI8Q9ly5ohqEePwqxZps+gb1+z9OaqVVZHJxxBEoEQIl0eHtCzp5mjMHWqWUynVStT82j3bqujE/YkiUAIkSEXF7OIzr59Zt3l1auhTh0YOhROn7Y6OmEPkgiEEJlSsCC8/ropfPf88zBpElSpAu++C3FxVkcnskMSgRDinpQoYcpW7N5thqGOHm1GGX37rVluU+Q9kgiEEFkSGAhz5pgZywEBZkKavz/UrAkvvGBKZV+6ZHWUIjOkxIQQItu0NqUrli83j9WrzVrLrq5mtNHDD5tHkyamE1rkvIxKTEgiEELYXUICbNx4MzGEhpp5CN7epjBe9+6mzlGxYlZH6jwkEQghLBUTA3//DcuWwYIFZtKam5u5S3j8cejSxfQ9CMeRRCCEyDW0NiUt5swxJbIPHzZNSK1amaTQrZtZYEfYlyQCIUSupDVERNxMCpGRZt5Cixbw2GPmTqFCBaujzB8kEQghcj2tYefOm0lhzx6zvUEDkxC6dIF69WTdhKySRCCEyHP274fff4d588z6CVpDxYqmk7lLF3PX4O5udZR5hyQCIUSeduYM/PGHSQzLlkF8PBQtaqqj1qoFvr7pPzw9M3f8lBQz0snV1azNkB9JIhBC5BtxcbB0qUkKCxdCdPSd9/XyguLFzTDV1FTzyz4hARITbz5PSLhZYtvDA15+Gd54I/+t1CaJQAiRb127BhcuwPnzd35cvHjzr/30Hh4e5ufOnTB9OpQrBx99ZMpv55c+CVmzWAiRbxUsCH5+5mEPw4bB8OGm4up335m6SkHp/vrMP6TWkBBCpHH//WZW9KRJptJqcDAMGmTWY8ivJBEIIcQtXFzg6afNyKWXX4YpU6BqVRgzBpKSrI7O/iQRCCHEHRQpAp9+Cjt2mDWdX3rJzGVYtMgMZ80vJBEIIcRdVK9uRigtWGBGHHXoAA0bwk8/5Y87BEkEQgiRCUpBp06waxdMnGiGnfbrB5Urw+efw5UrVkeYdZIIhBDiHhQoAAMGmKGmCxbAfffBK69A+fJmKc+TJ62O8N5JIhBCiCxwcTF3CKtWwaZN0KaN6U8ICDAdzTt3Wh1h5kkiEEKIbAoOhtmzTfXUoUPN8zp1zIpsI0bAtGmwd+/NGcy5jcwsFkIIOzt/HsaNg8WLYcsWs2wnQKFC0KiRmaDWuLH5WalSzsxelhITQghhkeRkczcQFmYW5AkLg23bzOgjMLWQ7rQQz60JYvRo6Nkza3FIiQkhhLCImxvUrm0eTz9ttiUmmrkJ4eGweTNcunT759L7G91RazxLIhBCiBzm4WGaiBo1sjoSw6GdxUqpdkqpfUqpA0qpkem8/7JSardSartSaoVSqqIj4xFCCHE7hyUCpZQr8C3QHqgJ9FZK1bxlt61AkNa6LjAH+NhR8QghhEifI+8IgoEDWutDWutEYBbQJe0OWuuVWmtbfzobAX8HxiOEECIdjkwEfsDxNK+jbNvuZCCwKL03lFJDlFLhSqnw6IyWIxJCCHHPcsWEMqVUPyAI+CS997XW47XWQVrroJIlS+ZscEIIkc85ctTQCaB8mtf+tm3/oJR6GHgDeFBrneDAeIQQQqTDkXcEYUCgUqqSUsoD6AXMT7uDUqoB8D3QWWudj9f/EUKI3MthiUBrnQwMA5YAe4DZWutdSql3lVKdbbt9AvgAvyilIpRS8+9wOCGEEA6S50pMKKWigaNZ/HgJ4Jwdw7GCXEPukR+uQ64hd8iJa6iotU63kzXPJYLsUEqF36nWRl4h15B75IfrkGvIHay+hlwxakgIIYR1JBEIIYSTc7ZEMN7qAOxAriH3yA/XIdeQO1h6DU7VRyCEEOJ2znZHIIQQ4haSCIQQwsk5TSK429oIeYFS6ohSaodt8l2eWK9TKTVJKXVWKbUzzbbiSqllSqlI208HrbtkH3e4hneUUids30WEUqqDlTHejVKqvFJqpW39j11KqRG27Xnmu8jgGvLMd6GU8lRKhSqlttmu4T+27ZWUUptsv59+tlVjyLm4nKGPwLY2wn7gEUwV1DCgt9Z6t6WB3SOl1BHM+g15ZvKMUqoFEAtM1VrXtm37GLigtf7QlpSLaa1ftzLOjNzhGt4BYrXWn1oZW2YppcoCZbXWW5RShYDNQFegP3nku8jgGnqQR74LpZQCvLXWsUopd2AtMAJ4GfhVaz1LKTUO2Ka1HptTcTnLHcFd10YQjqG1Xg1cuGVzF2CK7fkUzH/mXOsO15CnaK1Paa232J5fwZR98SMPfRcZXEOeoY1Y20t320MDrTGLc4EF34OzJIJ7XRsht9LAUqXUZqXUEKuDyYbSWutTtuengdJWBpMNw2zLrE7KzU0qt1JKBQANgE3k0e/ilmuAPPRdKKVclVIRwFlgGXAQiLHVZwMLfj85SyLIL5prrRtilv983tZkkadp0zaZF9snxwKVgfrAKeAza8PJHKWUDzAXeFFrfTnte3nlu0jnGvLUd6G1TtFa18eU5g8GqlscktMkgkytjZDbaa1P2H6eBX7D/CPKi87Y2nuvt/vmuRLkWusztv/QqcAE8sB3YWuTngv8pLX+1bY5T30X6V1DXvwuALTWMcBKoClQVCl1fX2YHP/95CyJ4K5rI+R2SilvWwcZSilvoA2wM+NP5VrzgX/Znv8L+N3CWLLk+i9Pm27k8u/C1kk5Edijtf48zVt55ru40zXkpe9CKVVSKVXU9rwgZgDLHkxCeNy2W45/D04xagjANqRsDOAKTNJaf2BxSPdEKXUf5i4AzMpyM/LCNSilZgItMWV2zwCjgXnAbKACpqR4D611ru2MvcM1tMQ0RWjgCDA0TVt7rqOUag6sAXYAqbbN/4dpY88T30UG19CbPPJdKKXqYjqDXTF/iM/WWr9r+/89CygObAX65eSKjU6TCIQQQqTPWZqGhBBC3IEkAiGEcHKSCIQQwslJIhBCCCcniUAIIZycJAIhcpBSqqVS6g+r4xAiLUkEQgjh5CQRCJEOpVQ/W934CKXU97ZCYbFKqS9sdeRXKKVK2vatr5TaaCt69tv1omdKqSpKqeW22vNblFKVbYf3UUrNUUrtVUr9ZJsxK4RlJBEIcQulVA2gJxBiKw6WAvQFvIFwrXUt4G/MDGOAqcDrWuu6mFmv17f/BHyrta4HNMMURANTNfNFoCZwHxDi8IsSIgNud99FCKfzENAICLP9sV4QU4wtFfjZts904FelVBGgqNb6b9v2KcAvtrpQflrr3wC01vEAtuOFaq2jbK8jgADMAiVCWEISgRC3U8AUrfWof2xU6q1b9stqfZa0NWRSkP+HwmLSNCTE7VYAjyulSsGNdX0rYv6/XK8Q2QdYq7W+BFxUSj1g2/4k8LdtBa0opVRX2zEKKKW8cvQqhMgk+UtEiFtorXcrpd7ErAbnAiQBzwNxQLDtvbOYfgQwZYPH2X7RHwKetm1/EvheKfWu7RhP5OBlCJFpUn1UiExSSsVqrX2sjkMIe5OmISGEcHJyRyCEEE5O7giEEMLJSSIQQggnJ4lACCGcnCQCIYRwcpIIhBDCyf0/xFbZPvp0ExUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished Training\n",
            "\n",
            "Average Testing Loss: 0.4748437866466502\n",
            "\n",
            "Average Testing Loss: 0.6252951260263983\n",
            "\n",
            "Testing on test set\n",
            "average validation loss: 0.882\n",
            "\n",
            "Generating Unlabeled Result\n",
            "\n",
            "Predicting on UH building image\n",
            "AP = 0.7304975842877504\n",
            "AP = 0.8300132456721424\n",
            "AP = 0.39178861744362575\n",
            "AP = 0.9029397115546622\n",
            "AP = 0.7310585798575578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Y9XuO0nUn4"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!zip -r ../segmentation_output.zip /content/segmentation/ # output_test /content/segmentation/output_train"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}